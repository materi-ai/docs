---
title: Scribe MCP Project Summary
description: Complete summary of Scribe Model Context Protocol implementation
icon: sparkles
source: /Users/alexarno/materi/platform/intelligence/.scribe/MCP_SUMMARY.md
sourceRepo: https://github.com/materi-ai/materi
lastMigrated: '2026-01-09T08:53:26.278673Z'
status: migrated
tags:
- scribe
- mcp
- summary
---

# Scribe Ã— n8n MCP Integration: Complete Setup

**Status**: âœ… Infrastructure Ready for Deployment
**Deployment Target**: hab.so1.io (Martian reference ðŸš€)
**Central Brain**: `/platform/intelligence/.scribe/` (Shelf Subsystem)

---

## What Was Created

### 1. Core MCP Package Structure

```
/platform/intelligence/.scribe/
â”œâ”€â”€ src/scribe/n8n/                          # âœ… NEW: n8n MCP package
â”‚   â”œâ”€â”€ __init__.py                          # Package exports
â”‚   â”œâ”€â”€ client.py                            # N8nMCPClient (async HTTP bridge)
â”‚   â”œâ”€â”€ workflow_manager.py                  # Workflow lifecycle mgmt
â”‚   â””â”€â”€ execution_monitor.py                 # Execution tracking & logging
â”‚
â”œâ”€â”€ src/scribe/config/
â”‚   â”œâ”€â”€ n8n_config.py                        # âœ… NEW: Configuration mgmt
â”‚   â””â”€â”€ workflow_definitions.yaml            # âœ… NEW: 4 workflow templates
â”‚
â”œâ”€â”€ src/scribe/observability/
â”‚   â”œâ”€â”€ n8n_metrics.py                       # âœ… NEW: Prometheus metrics
â”‚   â””â”€â”€ n8n_alerts.py                        # âœ… NEW: Discord alerting
â”‚
â”œâ”€â”€ .env.n8n.example                         # âœ… NEW: Config template
â”œâ”€â”€ N8N_MCP_INTEGRATION.md                   # âœ… NEW: Architecture doc
â”œâ”€â”€ SETUP_N8N_MCP.md                         # âœ… NEW: Setup guide
â””â”€â”€ MCP_SUMMARY.md                           # âœ… NEW: This file
```

### 2. Four n8n Workflows (Ready to Deploy)

| Workflow | Purpose | Trigger | Status |
|----------|---------|---------|--------|
| **Specification Ingestion** | Ingest CSV specs â†’ YAML requirements | Webhook POST | Defined âœ“ |
| **Cross-Reference Validation** | Validate requirement relationships | Daily 4 AM UTC | Defined âœ“ |
| **Documentation Publishing** | Generate MDX specs & mint.json | Daily 3 AM UTC | Defined âœ“ |
| **Performance SLA Reconciliation** | Track metrics vs SLA targets | Daily noon UTC | Defined âœ“ |

### 3. Observability Integration

- **Prometheus Metrics**: Workflow execution tracking (duration, status, errors)
- **Discord Alerts**: Real-time notifications for failures, timeouts, deployments
- **Execution Monitoring**: Async polling with timeout handling
- **Log Aggregation**: Ready for Loki integration

---

## Key Files & Purpose

### Architecture & Documentation
- **N8N_MCP_INTEGRATION.md**: Complete architecture design (10 sections)
- **SETUP_N8N_MCP.md**: Step-by-step deployment guide (10 phases)
- **MCP_SUMMARY.md**: This quickstart reference

### Core Implementation
- **client.py**: Async HTTP client wrapping n8n REST API
  - Methods: `health_check()`, `list_workflows()`, `create_workflow()`, `execute_workflow()`, `get_execution_status()`
  - Error handling with retry logic
  - Type-safe configuration management

- **workflow_manager.py**: Orchestrates workflow deployment
  - Load templates from YAML
  - Deploy workflows to n8n
  - Activate/test/monitor workflows
  - Track deployment state

- **execution_monitor.py**: Real-time execution tracking
  - Poll execution status until completion
  - Collect logs and metrics
  - Generate execution summaries
  - Batch monitoring support

### Configuration & Deployment
- **n8n_config.py**: Centralized config management (environment variables)
- **workflow_definitions.yaml**: 4 workflow templates ready to deploy
- **.env.n8n.example**: Template for credentials (copy & customize)

### Observability
- **n8n_metrics.py**: Prometheus metrics collection
  - `workflow_executions_total` (counter)
  - `workflow_execution_duration_seconds` (histogram)
  - `workflow_errors_total` (counter)
  - `workflow_active` (gauge)

- **n8n_alerts.py**: Discord integration
  - `alert_workflow_failure()`
  - `alert_workflow_success()`
  - `daily_summary()`
  - `deployment_notification()`

---

## How to Use: Quick Start

### Step 1: Configure Credentials

```bash
cd /Users/alexarno/materi/platform/intelligence/.scribe

# Copy example config
cp .env.n8n.example .env.n8n

# Add your credentials:
# - N8N_API_KEY from hab.so1.io settings
# - DISCORD_WEBHOOK_URL for alerts
# - Other optional observability URLs

source .env.n8n
```

### Step 2: Install & Test

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install package
pip install -e .
pip install httpx PyYAML prometheus-client

# Test connection
python3 << 'EOF'
import asyncio
import sys
sys.path.insert(0, 'src')

from scribe.n8n.client import N8nMCPClient

async def test():
    client = N8nMCPClient()
    health = await client.health_check()
    print('âœ“ Connected to n8n' if health else 'âœ— Connection failed')
    await client.close()

asyncio.run(test())
EOF
```

### Step 3: Deploy Workflows

```bash
python3 << 'EOF'
import asyncio
import sys
sys.path.insert(0, 'src')

from scribe.n8n.client import N8nMCPClient
from scribe.n8n.workflow_manager import WorkflowManager

async def deploy():
    client = N8nMCPClient()
    manager = WorkflowManager(client)
    await manager.load_workflow_templates()

    print("Deploying 4 workflows to hab.so1.io...")
    results = await manager.deploy_all_workflows()

    for name, wid in results.items():
        status = "âœ“" if wid else "âœ—"
        print(f"{status} {name}: {wid or 'failed'}")

    await client.close()

asyncio.run(deploy())
EOF
```

### Step 4: Monitor Executions

```bash
# Launch monitor daemon (polls every 60s)
bash cli/n8n_monitor.sh

# Or test single execution
python3 cli/n8n_orchestrate.py health
```

---

## Architecture Highlights

### MCP (Model-Context-Protocol) Pattern

The Scribe n8n integration implements MCP as:

1. **Client Layer** (`client.py`): HTTP bridge to n8n REST API
   - Async/await for non-blocking operations
   - Automatic retries with exponential backoff
   - Type-safe configuration from environment

2. **Manager Layer** (`workflow_manager.py`): Business logic abstraction
   - Loads workflow templates from YAML
   - Orchestrates deployment lifecycle
   - Tracks deployment state

3. **Monitoring Layer** (`execution_monitor.py`): Observability integration
   - Real-time execution tracking
   - Log collection and aggregation
   - Metrics for Prometheus export

### Observability-First Design

- **Metrics**: Prometheus scrape endpoint for workflow health
- **Logging**: Structured logs for each execution (ready for Loki)
- **Alerting**: Discord webhooks for failures and summaries
- **Tracing**: Execution IDs link workflow runs across systems

---

## Workflow Definitions Explained

### 1. Specification Ingestion Workflow

**Purpose**: Import CSV specifications into Traceo engine

```yaml
Trigger (webhook)
  â†’ CSV Validator (Python)
  â†’ Traceo Ingestion (HTTP POST)
  â†’ Discord Notification
```

**Automated via**: Manual webhook or n8n REST API

### 2. Cross-Reference Validation Workflow

**Purpose**: Validate requirement relationships daily

```yaml
Schedule (04:00 UTC)
  â†’ Validate Relationships (python validate_relationships.py)
  â†’ Parse Results (extract pass/fail)
  â†’ Generate Report (read markdown)
  â†’ Discord Alert
```

**Benefits**: Catch broken references automatically

### 3. Documentation Publishing Workflow

**Purpose**: Generate MDX specs from requirements

```yaml
Schedule (03:00 UTC)
  â†’ Query Requirements (HTTP)
  â†’ Generate Specs (python script)
  â†’ Create Navigation (mint.json)
  â†’ Publish Docs (npm build)
```

**Output**: MDX specifications in `/platform/atlas/`

### 4. Performance SLA Reconciliation Workflow

**Purpose**: Track metrics against SLA targets

```yaml
Schedule (12:00 UTC)
  â†’ Fetch Metrics (Prometheus query)
  â†’ Compare to SLA (Python)
  â†’ Create GitHub Issue (if violations)
  â†’ Alert Discord
```

**SLA Targets** (from NFR-001):
- API response: <50ms P95
- Collaboration sync: <25ms P95
- Permission validation: <1ms P99
- Shield auth: <15ms P95

---

## Integration Points

### With Traceo Requirement Engine

```
Ingestion Workflow
  â†“
/requirements/*.yml (718 files)
  â†“
Validation Workflow
  â†“
RELATIONSHIP_VALIDATION_REPORT.md
```

### With Observability Stack

```
Execution Monitor
  â†“
Prometheus Metrics
  â†“
Grafana Dashboard
```

```
Execution Logs
  â†“
Loki Log Aggregation
  â†“
Grafana Loki Queries
```

```
Workflow Failures
  â†“
Discord Alerts
  â†“
Team Notification
```

---

## Environment Variables Reference

**Required:**
- `N8N_HOST`: hab.so1.io
- `N8N_API_KEY`: From n8n Settings â†’ API
- `N8N_WEBHOOK_URL`: https://hab.so1.io/webhook

**Optional but Recommended:**
- `DISCORD_WEBHOOK_URL`: For alerts
- `PROMETHEUS_PUSHGATEWAY_URL`: For metrics
- `LOKI_URL`: For log aggregation

**Data Paths:**
- `REQUIREMENTS_DIR`: `/Users/alexarno/materi/requirements`
- `TRACEABILITY_MATRIX_PATH`: `/Users/alexarno/materi/traceability_matrix.json`
- `SPECS_OUTPUT_DIR`: `/Users/alexarno/materi/platform/atlas/specs`

---

## Next Steps

1. **âœ… Phase 1-3 Complete**: MCP infrastructure created, configuration template ready
2. **â­ï¸ Phase 4**: Copy `.env.n8n.example` â†’ `.env.n8n`, add your credentials
3. **â­ï¸ Phase 5**: Test connection with health check script
4. **â­ï¸ Phase 6**: Deploy 4 workflows to hab.so1.io
5. **â­ï¸ Phase 7**: Test each workflow with sample data
6. **â­ï¸ Phase 8**: Set up Prometheus scraping
7. **â­ï¸ Phase 9**: Configure Grafana dashboard
8. **â­ï¸ Phase 10**: Integrate with CI/CD pipeline

---

## Troubleshooting Checklist

- [ ] Can ping hab.so1.io from your machine?
- [ ] Is N8N_API_KEY valid? (check n8n Settings)
- [ ] Does `.env.n8n` exist with correct values?
- [ ] Virtual environment activated? (`source .venv/bin/activate`)
- [ ] Dependencies installed? (`pip install -e .`)
- [ ] Health check passes? (see Step 2 above)

---

## Key Design Decisions

| Decision | Rationale |
|----------|-----------|
| Async/Await (httpx) | Non-blocking I/O for workflow orchestration |
| YAML Templates | Version-controllable workflow definitions |
| Discord Webhooks | Real-time team alerting (lightweight) |
| Prometheus Metrics | Industry-standard observability collection |
| Environment Variables | Secure credential management, no hardcoding |
| MCP Pattern | Abstraction layer for future n8n upgrades |

---

## File Sizes & Complexity

| File | Lines | Purpose |
|------|-------|---------|
| client.py | 150 | Core HTTP client |
| workflow_manager.py | 70 | Lifecycle management |
| execution_monitor.py | 120 | Execution tracking |
| n8n_metrics.py | 100 | Prometheus export |
| n8n_alerts.py | 180 | Discord alerting |
| workflow_definitions.yaml | 300+ | 4 complete workflows |

**Total**: ~920 lines of production-ready code

---

## References

- **n8n API**: https://docs.n8n.io/api/
- **MCP Protocol**: https://modelcontextprotocol.io/
- **Scribe Core**: `STANDUP_SYSTEM.md`
- **Requirements**: 718 YAML definitions in `/requirements/`
- **Traceability**: `TRACEABILITY_MATRIX.md`

---

## Support

For detailed setup instructions, see: **SETUP_N8N_MCP.md** (10 phases)
For architecture details, see: **N8N_MCP_INTEGRATION.md** (12 sections)

Happy automation! ðŸš€
